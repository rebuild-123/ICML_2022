{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac8a951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# from src.model import *\n",
    "# from src.util import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "259f0a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_path = '/workdir/security/home/junjiehuang2468/paper/trained_models_weight/kaggle_miscrosoft/'\n",
    "data_path = \"/workdir/security/home/junjiehuang2468/paper/data/kaggle/\"\n",
    "train_data_path = data_path + \"malwares/\"  # Training data\n",
    "train_label_path = data_path + \"train_labels.csv\"  # Training label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d05d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = True if torch.cuda.is_available() else False\n",
    "NUM_WORKERS = 16  # Number of cores to use for data loader\n",
    "BATCH_SIZE = 128  #\n",
    "LEAVE_BIT_NUMBER = 500000\n",
    "KERNEL_SIZE = 500  # Kernel size & stride for Malconv (defualt : 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29136ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.read_csv(data_path + 'train_dataset.csv')\n",
    "validset = pd.read_csv(data_path + 'valid_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b5c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExeDataset(Dataset):\n",
    "    def __init__(self, malware_names, data_path, labels, leave_bit_num):\n",
    "        self.malware_names = malware_names\n",
    "        self.data_path = data_path\n",
    "        self.labels = labels\n",
    "        self.leave_bit_num = leave_bit_num\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.malware_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with open(self.data_path + self.malware_names[idx] + '.txt','rb') as fp:\n",
    "            data = [bit+1 for bit in fp.read()[:self.leave_bit_num]]\n",
    "            padding = [0]*(self.leave_bit_num-len(data))\n",
    "            data = data + padding\n",
    "\n",
    "        return np.array(data), np.array([self.labels[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07c21ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ExeDataset(\n",
    "    trainset[\"id\"].tolist(), \n",
    "    train_data_path, \n",
    "    trainset[\"labels\"].tolist(), \n",
    "    LEAVE_BIT_NUMBER\n",
    ")\n",
    "valid_dataset = ExeDataset(\n",
    "    validset[\"id\"].tolist(), \n",
    "    train_data_path, \n",
    "    validset[\"labels\"].tolist(), \n",
    "    LEAVE_BIT_NUMBER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58c7ba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = False,\n",
    "    num_workers = NUM_WORKERS,\n",
    "    pin_memory = True\n",
    ")\n",
    "validloader = DataLoader(\n",
    "    dataset = valid_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = False,\n",
    "    num_workers = NUM_WORKERS,\n",
    "    pin_memory = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4050dbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MalConv(nn.Module):\n",
    "#     def __init__(self, input_length=2000000, window_size=500):\n",
    "#         super(MalConv, self).__init__()\n",
    "\n",
    "#         self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "\n",
    "#         self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "#         self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "\n",
    "#         self.BatchNorm1d = nn.BatchNorm1d(128)\n",
    "\n",
    "#         self.pooling = nn.MaxPool1d(int(input_length / window_size))\n",
    "\n",
    "#         self.fc_1 = nn.Linear(128, 128)\n",
    "#         self.fc_2 = nn.Linear(128, 9)\n",
    "\n",
    "#         # self.BatchNorm1d = nn.BatchNorm1d(128)\n",
    "\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#     # self.softmax = nn.Softmax()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.embed(x)\n",
    "#         # Channel first\n",
    "#         x = torch.transpose(x, -1, -2)\n",
    "\n",
    "#         cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "#         cnn_value = self.BatchNorm1d(cnn_value)\n",
    "#         gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "\n",
    "#         x = cnn_value * gating_weight\n",
    "#         x = self.pooling(x)\n",
    "\n",
    "#         x = x.view(-1, 128)\n",
    "#         x = self.fc_1(x)\n",
    "#         # x = self.BatchNorm1d(x)\n",
    "#         x = self.fc_2(x)\n",
    "#         # x = self.sigmoid(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae31abcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, data_length = 2e6, kernel_size = 500):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_layer_1 = nn.Conv1d(4, 128, kernel_size, stride = kernel_size, bias = True)\n",
    "        # self.bn_1 = nn.BatchNorm1d(128)\n",
    "        self.conv_layer_2 = nn.Conv1d(4, 128, kernel_size, stride = kernel_size, bias = True)\n",
    "        self.pool_layer_2 = nn.MaxPool1d(data_length//kernel_size)\n",
    "        self.fc_layer_3 = nn.Linear(128, 128)\n",
    "        self.fc_layer_4 = nn.Linear(128, 9)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.transpose(-1,-2)\n",
    "        x_conv_1 = self.conv_layer_1(x[:,:4,:])\n",
    "        x_conv_2 = torch.sigmoid(self.conv_layer_2(x[:,4:,:]))\n",
    "        x = x_conv_1*x_conv_2\n",
    "        del x_conv_1,x_conv_2\n",
    "        x = self.pool_layer_2(x).squeeze()\n",
    "        x = self.fc_layer_3(x)\n",
    "        x = self.fc_layer_4(x)\n",
    "        # x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79fd8336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mp_func(i,inpu,te,gr):\n",
    "#     check = 0\n",
    "#     for j,(inp,g,t) in enumerate(zip(inpu,gr,te)):\n",
    "#         if inp != 0: \n",
    "#             check = j\n",
    "#             continue\n",
    "#         max_idx = np.argmin(g).tolist()\n",
    "#         org_max_idx = np.argmax(t).tolist()\n",
    "#         if g[max_idx] > 0: continue\n",
    "#         te[j][org_max_idx] = 0\n",
    "#         te[j][max_idx] = 1\n",
    "#     return [i,te,check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6189222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MalConv(nn.Module):\n",
    "#     def __init__(self, input_length=2000000, window_size=500):\n",
    "#         super(MalConv, self).__init__()\n",
    "\n",
    "#         self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "\n",
    "#         self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "#         self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "\n",
    "#         self.BatchNorm1d = nn.BatchNorm1d(128)\n",
    "\n",
    "#         self.pooling = nn.MaxPool1d(int(input_length / window_size))\n",
    "\n",
    "#         self.fc_1 = nn.Linear(128, 128)\n",
    "#         self.fc_2 = nn.Linear(128, 9)\n",
    "\n",
    "#         # self.BatchNorm1d = nn.BatchNorm1d(128)\n",
    "\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#     # self.softmax = nn.Softmax()\n",
    "    \n",
    "#     def forward(self, input_, loss_fn, fake_label, label):\n",
    "#         temp = F.one_hot(input_,num_classes=257).float()\n",
    "#         temp.requires_grad = True\n",
    "#         temp.retain_grad()\n",
    "#         for _ in range(10):\n",
    "#             x = temp @ self.embed.weight\n",
    "#             x = torch.transpose(x, -1, -2)\n",
    "#             cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "#             cnn_value = self.BatchNorm1d(cnn_value)\n",
    "#             gating_weight = self.sigmoid(malconv.conv_2(x.narrow(-2, 4, 4)))\n",
    "#             x = cnn_value * gating_weight\n",
    "#             x = self.pooling(x)\n",
    "#             x = x.view(-1, 128)\n",
    "#             x = self.fc_1(x)\n",
    "#             x = self.fc_2(x)\n",
    "            \n",
    "#             print((torch.argmax(torch.softmax(x,dim=-1),dim=-1) == label).float().mean())\n",
    "            \n",
    "#             loss = loss_fn(x,fake_label).cuda()\n",
    "#             print(loss)\n",
    "#             loss.backward()\n",
    "            \n",
    "#             data = [(i,inpu,te,gr) for i,(inpu,te,gr) in enumerate(zip(\n",
    "#                 input_.detach().cpu().numpy(),\n",
    "#                 temp.detach().cpu().numpy(),\n",
    "#                 temp.grad.detach().cpu().numpy()\n",
    "#             ))]\n",
    "#             with mp.Pool(processes=24 if len(data) > 24 else len(data)) as pool:\n",
    "#                 results = pool.starmap(mp_func,data)\n",
    "            \n",
    "#             print(sum(r[2] for r in results)/len(results))\n",
    "#             results = sorted(results,key = lambda x: x[0])\n",
    "#             for i in range(len(temp)):\n",
    "#                 temp.data[i] = torch.tensor(results[i][1], dtype=torch.float, requires_grad=True).cuda()\n",
    "                \n",
    "#         return x.cpu().detach().numpy(),temp.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdcaaac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_def(model,trainloader,loss_fn,optim,cuda=True):\n",
    "    model.train()\n",
    "    ls = []\n",
    "    bar = tqdm(trainloader)\n",
    "    for step, (batch_data,batch_label) in enumerate(bar):\n",
    "        optim.zero_grad()\n",
    "        batch_data = batch_data.cuda() if cuda else batch_data\n",
    "        batch_label = batch_label.cuda() if cuda else batch_label\n",
    "        batch_label = batch_label.squeeze() - 1\n",
    "\n",
    "        pred = model(batch_data)\n",
    "        loss = loss_fn(pred, batch_label)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        _, predicted = torch.max(pred, 1)\n",
    "        temp_ls = (batch_label.cpu().data.numpy() == predicted.cpu().data.numpy()).tolist()\n",
    "        ls.extend(temp_ls)\n",
    "        bar.set_description(f'train: {np.mean(ls):.6}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2a81f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_def(model,validloader,cuda=True):\n",
    "    model.eval()\n",
    "    ls = []\n",
    "    bar = tqdm(validloader)\n",
    "    for step, (batch_data,batch_label) in enumerate(bar):\n",
    "        optim.zero_grad()\n",
    "        batch_data = batch_data.cuda() if cuda else batch_data\n",
    "        batch_label = batch_label.cuda() if cuda else batch_label\n",
    "        batch_label = batch_label.squeeze() - 1\n",
    "\n",
    "        pred = model(batch_data)\n",
    "        _, predicted = torch.max(pred, 1)\n",
    "        temp_ls = (batch_label.cpu().data.numpy() == predicted.cpu().data.numpy()).tolist()\n",
    "        ls.extend(temp_ls)\n",
    "        bar.set_description(f'test: {np.mean(ls):.6}')\n",
    "    return model,np.mean(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d11a0c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(data_length=LEAVE_BIT_NUMBER,kernel_size=KERNEL_SIZE)\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "optim = Adam(model.parameters())\n",
    "\n",
    "model = model.cuda() if CUDA else model\n",
    "ce_loss = ce_loss.cuda() if CUDA else ce_less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85c0ebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dir = str(datetime.now())\n",
    "time_dir = time_dir[:time_dir.rfind(':')]\n",
    "os.mkdir(f'{trained_model_path}{time_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79382af7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.742121: 100%|██████████| 68/68 [01:31<00:00,  1.35s/it]\n",
      "test: 0.905704: 100%|██████████| 17/17 [00:29<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.933517: 100%|██████████| 68/68 [01:42<00:00,  1.51s/it]\n",
      "test: 0.912144: 100%|██████████| 17/17 [00:33<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.971935: 100%|██████████| 68/68 [01:39<00:00,  1.47s/it]\n",
      "test: 0.934683: 100%|██████████| 17/17 [00:31<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.989878: 100%|██████████| 68/68 [01:37<00:00,  1.44s/it]\n",
      "test: 0.935603: 100%|██████████| 17/17 [00:29<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.990683: 100%|██████████| 68/68 [01:43<00:00,  1.52s/it]\n",
      "test: 0.925023: 100%|██████████| 17/17 [00:31<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.995629: 100%|██████████| 68/68 [01:31<00:00,  1.35s/it]\n",
      "test: 0.940662: 100%|██████████| 17/17 [00:39<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.995514: 100%|██████████| 68/68 [01:43<00:00,  1.52s/it]\n",
      "test: 0.937443: 100%|██████████| 17/17 [00:32<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.997815: 100%|██████████| 68/68 [01:41<00:00,  1.49s/it]\n",
      "test: 0.953082: 100%|██████████| 17/17 [00:32<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.9977: 100%|██████████| 68/68 [01:32<00:00,  1.36s/it]  \n",
      "test: 0.958142: 100%|██████████| 17/17 [00:32<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.9977: 100%|██████████| 68/68 [01:41<00:00,  1.49s/it]  \n",
      "test: 0.954462: 100%|██████████| 17/17 [00:31<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.998045: 100%|██████████| 68/68 [01:39<00:00,  1.46s/it]\n",
      "test: 0.945722: 100%|██████████| 17/17 [00:30<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.997239: 100%|██████████| 68/68 [01:40<00:00,  1.47s/it]\n",
      "test: 0.946182: 100%|██████████| 17/17 [00:30<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.99793: 100%|██████████| 68/68 [01:36<00:00,  1.42s/it] \n",
      "test: 0.949402: 100%|██████████| 17/17 [00:33<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.99747: 100%|██████████| 68/68 [01:32<00:00,  1.35s/it] \n",
      "test: 0.941122: 100%|██████████| 17/17 [00:33<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.998275: 100%|██████████| 68/68 [01:46<00:00,  1.57s/it]\n",
      "test: 0.961362: 100%|██████████| 17/17 [00:32<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.99839: 100%|██████████| 68/68 [01:41<00:00,  1.49s/it] \n",
      "test: 0.961822: 100%|██████████| 17/17 [00:32<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.998505: 100%|██████████| 68/68 [01:37<00:00,  1.44s/it]\n",
      "test: 0.960902: 100%|██████████| 17/17 [00:36<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.998735: 100%|██████████| 68/68 [01:49<00:00,  1.61s/it]\n",
      "test: 0.960442: 100%|██████████| 17/17 [00:31<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.998735: 100%|██████████| 68/68 [01:44<00:00,  1.53s/it]\n",
      "test: 0.960442: 100%|██████████| 17/17 [00:34<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.998735: 100%|██████████| 68/68 [01:39<00:00,  1.46s/it]\n",
      "test: 0.959982: 100%|██████████| 17/17 [00:35<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.998735: 100%|██████████| 68/68 [01:44<00:00,  1.53s/it]\n",
      "test: 0.960902: 100%|██████████| 17/17 [00:34<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.998735: 100%|██████████| 68/68 [01:47<00:00,  1.58s/it]\n",
      "test: 0.959982: 100%|██████████| 17/17 [00:35<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.998735: 100%|██████████| 68/68 [01:46<00:00,  1.57s/it]\n",
      "test: 0.960442: 100%|██████████| 17/17 [00:34<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.998735: 100%|██████████| 68/68 [01:36<00:00,  1.42s/it]\n",
      "test: 0.958602: 100%|██████████| 17/17 [00:37<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.998735: 100%|██████████| 68/68 [01:35<00:00,  1.40s/it]\n",
      "test: 0.959982: 100%|██████████| 17/17 [00:34<00:00,  2.01s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    print(i)\n",
    "    model = train_def(model,trainloader,ce_loss,optim,CUDA)\n",
    "    model,test_acc = valid_def(model,validloader,CUDA)\n",
    "    save_path = f'{trained_model_path}{time_dir}/50w_epoch:{i}_test_acc:{test_acc:.6f}.pt'\n",
    "    torch.save(model.state_dict(),save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
