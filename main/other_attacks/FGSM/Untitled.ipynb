{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28ec0d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from MalConv import MalConv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import struct\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "822338b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 512\n",
    "eps = 0.7\n",
    "target = 0  # benign\n",
    "loop_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53674e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction(x, y):\n",
    "    \"\"\"\n",
    "    reconstruction restore original bytes from embedding matrix.\n",
    "\n",
    "    Args:\n",
    "        x torch.Tensor:\n",
    "            x is word embedding\n",
    "\n",
    "        y torch.Tensor:\n",
    "            y is embedding matrix\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor:\n",
    "    \"\"\"\n",
    "    x_size = x.size()[0]\n",
    "    y_size = y.size()[0]\n",
    "    # print(x_size, y_size)\n",
    "\n",
    "    z = torch.zeros(x_size)\n",
    "\n",
    "    for i in tqdm(range(x_size)):\n",
    "        dist = torch.zeros(256)\n",
    "\n",
    "        for j in range(y_size):\n",
    "            dist[j] = torch.dist(x[i], y[j])  # computation of euclidean distance\n",
    "\n",
    "        z[i] = dist.argmin()\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b441c007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(sys.argv[1], 'rb') as f:\n",
    "#     bytez = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bb5be89",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_path = '/workdir/security/home/junjiehuang2468/paper/trained_models_weight/ember/'\n",
    "best_trained_model = '2022-01-18 14:55/2w_epoch:13_test_acc:0.896058.pt'\n",
    "data_path = \"/workdir/security/home/junjiehuang2468/paper/data/ember2018/\"\n",
    "train_data_path = data_path + \"malwares/\" \n",
    "train_label_path = data_path + \"train_labels.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deaebffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.read_csv(data_path + 'train_dataset.csv')\n",
    "validset = pd.read_csv(data_path + 'valid_dataset.csv')\n",
    "validset = validset.iloc[np.argwhere(validset['labels'].values == 1).squeeze(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fe33ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEAVE_BIT_NUMBER = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7584e127",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_data_path + trainset[\"id\"].tolist()[0] + '.txt','rb') as fp:\n",
    "    data = [bit+1 for bit in fp.read()[:LEAVE_BIT_NUMBER]]\n",
    "    padding = [0]*(LEAVE_BIT_NUMBER-len(data))\n",
    "    data = data + padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38dbd0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bytez = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a51402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create malconv\n",
    "malconv = MalConv(channels=256, window_size=512, embd_size=8)\n",
    "weights = torch.load('./malconv.checkpoint', map_location='cpu')\n",
    "malconv.load_state_dict(weights['model_state_dict'])\n",
    "malconv.eval()\n",
    "\n",
    "# Create optimizer\n",
    "opt = torch.optim.SGD(malconv.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Compute payload size\n",
    "payload_size = kernel_size + (kernel_size - np.mod(len(bytez), kernel_size))\n",
    "\n",
    "# Creat embedding matrix\n",
    "embed = malconv.embd\n",
    "m = embed(torch.arange(0, 256))\n",
    "\n",
    "# Make label from target\n",
    "label = torch.tensor([target], dtype=torch.long)\n",
    "\n",
    "perturbation = np.random.randint(0, 256, payload_size, dtype=np.uint8)\n",
    "\n",
    "# Make input file x as numpy array\n",
    "# x = np.frombuffer(bytez, dtype=np.uint8)\n",
    "x = np.array(bytez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "461cc738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20992)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([x, perturbation])[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53a5a297",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Benign: 0.096648 , Malicious: 0.90335\n",
      "Loss: 1.1757\n",
      "Reconstruction phase:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 992/992 [00:04<00:00, 220.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of perturbation:  125291.0 \n",
      "\n",
      "[2]\n",
      "Benign: 1 , Malicious: 1.8236e-14\n",
      "Loss: 0.31326\n",
      "Reconstruction phase:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 992/992 [00:04<00:00, 199.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of perturbation:  122779.0 \n",
      "\n",
      "[3]\n",
      "Benign: 1 , Malicious: 2.2009e-36\n",
      "Loss: 0.31326\n",
      "Reconstruction phase:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 992/992 [00:04<00:00, 206.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of perturbation:  126310.0 \n",
      "\n",
      "[4]\n",
      "Benign: 1 , Malicious: 0\n",
      "Loss: 0.31326\n",
      "Reconstruction phase:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 992/992 [00:05<00:00, 192.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of perturbation:  126310.0 \n",
      "\n",
      "[5]\n",
      "Benign: 1 , Malicious: 0\n",
      "Loss: 0.31326\n",
      "Reconstruction phase:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 992/992 [00:05<00:00, 195.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of perturbation:  126310.0 \n",
      "\n",
      "[6]\n",
      "Benign: 1 , Malicious: 0\n",
      "Loss: 0.31326\n",
      "Reconstruction phase:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 992/992 [00:05<00:00, 190.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of perturbation:  126310.0 \n",
      "\n",
      "[7]\n",
      "Benign: 1 , Malicious: 0\n",
      "Loss: 0.31326\n",
      "Reconstruction phase:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 992/992 [00:04<00:00, 223.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of perturbation:  126310.0 \n",
      "\n",
      "[8]\n",
      "Benign: 1 , Malicious: 0\n",
      "Loss: 0.31326\n",
      "Reconstruction phase:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 992/992 [00:04<00:00, 215.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of perturbation:  126310.0 \n",
      "\n",
      "[9]\n",
      "Benign: 1 , Malicious: 0\n",
      "Loss: 0.31326\n",
      "Reconstruction phase:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 992/992 [00:04<00:00, 198.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of perturbation:  126310.0 \n",
      "\n",
      "[10]\n",
      "Benign: 1 , Malicious: 0\n",
      "Loss: 0.31326\n",
      "Reconstruction phase:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 992/992 [00:04<00:00, 202.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of perturbation:  126310.0 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in range(loop_num):\n",
    "    print('[{}]'.format(str(i + 1)))\n",
    "    opt.zero_grad()  # initialize grad\n",
    "\n",
    "    # Make input of malconv\n",
    "    inp = torch.from_numpy(np.concatenate([x, perturbation])[np.newaxis, :]).float()\n",
    "    inp_adv = inp.requires_grad_()\n",
    "    embd_x = embed(inp_adv.long()).detach()\n",
    "    embd_x.requires_grad = True\n",
    "    # embd_x.retain_grad()\n",
    "\n",
    "    outputs = malconv(embd_x)\n",
    "    results = F.softmax(outputs, dim=1)\n",
    "\n",
    "    r = results.detach().numpy()[0]\n",
    "    print('Benign: {:.5g}'.format(r[0]), ', Malicious: {:.5g}'.format(r[1]))\n",
    "\n",
    "    # Compute loss\n",
    "    loss = nn.CrossEntropyLoss()(results, label)\n",
    "    print('Loss: {:.5g}'.format(loss.item()))\n",
    "\n",
    "    # Update\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    grad = embd_x.grad\n",
    "    grad_sign = grad.detach().sign()[0][-payload_size:]  # extract only grad_sign of perturbation\n",
    "\n",
    "    # Change types to numpy to prevent Error: Leaf variable was used in an inplace operation\n",
    "    perturbation = embed(torch.from_numpy(perturbation).long())\n",
    "\n",
    "    # Compute perturbation\n",
    "    perturbation = (perturbation - eps * grad_sign).detach().numpy()\n",
    "\n",
    "    embd_x = embd_x.detach().numpy()\n",
    "    embd_x[0][-payload_size:] = perturbation  # update perturbation\n",
    "\n",
    "    print('Reconstruction phase:')\n",
    "    perturbation = reconstruction(torch.from_numpy(perturbation), m).detach().numpy()\n",
    "    print('sum of perturbation: ', perturbation.sum(), '\\n')  # for debug\n",
    "\n",
    "#     # Generate perturbation file\n",
    "#     with open('perturb.bin', 'wb') as out:\n",
    "#         for s in perturbation:\n",
    "#             out.write(struct.pack('B', int(s)))\n",
    "\n",
    "#     # Make a decision on evasion rates\n",
    "#     if results[0][0] > 0.5:\n",
    "#         print('Evasion rates: {:.5g}'.format(results[0][0].item()), '\\n')\n",
    "#         aes_name = os.path.splitext(sys.argv[1])[0] + '_AEs.exe'\n",
    "\n",
    "#         with open(aes_name, 'wb') as out:\n",
    "#             aes = np.concatenate([x, perturbation.astype(np.uint8)])\n",
    "\n",
    "#             for s in aes:\n",
    "#                 out.write(struct.pack('B', int(s)))\n",
    "\n",
    "#         print(aes_name, ' has been created.')\n",
    "        \n",
    "#         break\n",
    "\n",
    "# print('Adversarial Examples is not found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67ba43d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 55., 157., 244., 230., 213.,  70.,  51., 165., 221.,  16., 219.,\n",
       "        26.,  51.,  48.,   9., 122.,   4., 105., 246., 239.,  21., 133.,\n",
       "       216., 126., 196., 113., 166., 193.,  52.,  73.,  65.,  22.,  69.,\n",
       "        46., 236., 184., 137., 209., 123., 129., 243., 181., 101.,  66.,\n",
       "       187., 100.,  73.,  20.,  14., 132.,  49., 197., 221., 154., 109.,\n",
       "       108.,  60., 140., 184., 151.,  67., 186., 117., 142.,  67., 255.,\n",
       "        78., 187.,  49., 108., 238.,  94., 138., 193., 109.,  96., 206.,\n",
       "        33., 188.,  30.,  27., 142., 163., 106.,  59., 210., 181., 120.,\n",
       "        45., 111., 238., 239., 244., 144., 125., 138., 214.,  57., 208.,\n",
       "         9.,  28., 132., 115.,  12., 155., 254., 240., 107.,  92., 209.,\n",
       "         2.,  62.,  31., 165.,  85., 154.,  11.,  94., 248.,  35., 243.,\n",
       "        94., 104., 249.,   5., 246.,  69.,  59.,  22., 215., 243., 152.,\n",
       "        88., 235., 217., 150.,  61.,  50.,  79.,  89.,  20.,  32., 181.,\n",
       "       180., 241., 203., 252., 206., 186.,  93.,  79., 217., 162.,  30.,\n",
       "        35., 226.,  10.,  17., 202.,  28.,  49.,  28.,   9.,  18., 223.,\n",
       "       220., 204., 223., 136.,  95.,  31., 253., 156., 179., 165., 134.,\n",
       "         5., 151.,  11.,  98., 125., 132., 239.,  49., 152.,  74., 156.,\n",
       "       173.,  23.,  65., 189., 124.,  31., 118.,  29., 163.,  18., 167.,\n",
       "       141., 138.,  79., 243.,   2., 184., 222., 219., 140., 230., 209.,\n",
       "       139., 232., 132., 122., 231.,  37., 222., 141.,  36.,  40., 231.,\n",
       "       248.,  93., 125., 243., 120., 189., 132., 229., 146.,  64., 190.,\n",
       "       254., 254., 138., 173., 136., 183., 130., 250.,  44., 188.,  53.,\n",
       "       139., 180.,  93., 214., 142., 167., 114., 251., 168., 112., 182.,\n",
       "        66.,  43.,  89., 141., 156.,  40., 202.,  23., 177., 166.,  36.,\n",
       "       124.,  53., 235., 230.,  96., 239.,  49., 217.,  50.,   5.,  79.,\n",
       "        42., 159., 243., 232., 140., 134., 202., 250., 209., 220., 236.,\n",
       "       143., 236.,  93.,  52.,  14.,  15., 229., 143., 241., 203.,  87.,\n",
       "       138., 159., 107., 142.,  35., 101.,  73., 128., 237.,  11., 154.,\n",
       "       120., 202., 138., 102.,  86., 104., 184., 212.,  57.,  25., 114.,\n",
       "       194., 137., 202.,  15.,  32., 217., 192., 207., 239., 172., 223.,\n",
       "        14., 149., 151.,  80., 251., 128.,   4., 225.,  15., 127.,  58.,\n",
       "        50.,  59., 188., 218., 104., 143., 179.,  44., 145., 212.,  75.,\n",
       "       130., 214., 243.,  47.,  65., 150.,  94., 169.,  30.,  96., 165.,\n",
       "        94.,  40., 186., 106.,  46.,  54.,   1.,  38.,  23., 226., 175.,\n",
       "       239.,  27.,  33.,  26.,  16., 255., 220.,   5.,  21., 108.,  80.,\n",
       "       145., 239., 231., 113.,  87., 219., 144.,  12., 245., 111., 146.,\n",
       "        82., 223., 158., 238., 221., 174., 150.,  86.,  68.,   1.,  84.,\n",
       "        21., 212., 107., 229., 227., 127., 124., 166.,   1., 167.,  67.,\n",
       "       111.,  90.,   2., 209.,  20.,  65., 134., 243.,  78.,  87., 241.,\n",
       "        12.,  43., 211.,   9., 183., 183., 135.,  89., 126., 246.,  99.,\n",
       "       181., 156., 208.,  45.,   3.,  55., 216., 142.,   7., 112., 114.,\n",
       "       129., 223.,  54., 142., 223., 248., 172.,  75.,  89.,  44., 160.,\n",
       "        64., 176.,  75., 176., 104., 235.,  42., 210.,  26.,  92.,  77.,\n",
       "        65.,  89.,  23., 229., 194., 128., 254.,  69., 147., 240., 232.,\n",
       "        10., 217., 204.,  38.,  84.,  15., 188., 186.,  28., 156., 139.,\n",
       "       175., 175., 166.,  62.,  82., 135., 118.,  20.,  79., 253., 160.,\n",
       "       122., 160.,  28., 237.,  78., 216.,  49.,   4., 163.,  28., 166.,\n",
       "       137., 163., 160., 251.,  99., 143., 195.,  65., 120.,  34., 171.,\n",
       "       125., 178., 229.,   9., 132., 175., 100.,  80., 100., 155., 224.,\n",
       "        45., 171.,  28., 231., 142., 111., 221., 112.,  53., 159., 213.,\n",
       "        65.,  21., 228., 175.,   9., 208., 161., 240., 207., 177., 140.,\n",
       "        67., 144.,   2.,  21., 205., 104., 139.,  65.,  11., 164., 140.,\n",
       "       223.,  94., 144., 137., 155.,   2., 103., 158.,  92., 156., 155.,\n",
       "        94., 175., 107.,  54., 138., 224., 203.,  68., 195.,  54.,  65.,\n",
       "       225., 182., 143., 198., 111., 177., 141.,  80.,  49., 235.,  65.,\n",
       "       233., 205., 243.,  73., 202.,  45., 111.,  39.,  80., 141., 194.,\n",
       "        65.,  54.,  54., 175., 226., 200.,  45.,   3., 232., 218., 127.,\n",
       "       229.,  28., 180.,   8., 241.,  46., 163., 169.,  73.,  17., 101.,\n",
       "       193., 165., 148., 156.,  23., 226., 186.,  33., 185.,  98.,  21.,\n",
       "       132.,  31.,   9.,  37., 175.,   5.,  20., 149., 195., 191.,  61.,\n",
       "       208., 128.,  35.,  87.,  75., 125., 186.,  98., 123., 166.,  20.,\n",
       "        53., 178., 226.,  65.,  39., 226., 208.,   8., 151., 103., 166.,\n",
       "        12., 243.,  53.,  21., 177.,  91.,  56.,  81., 177., 154.,  39.,\n",
       "       223.,  79.,  96., 236., 105.,  71., 113., 173.,  57., 193.,  69.,\n",
       "       222., 248., 121., 230., 207., 195.,  25.,  36., 212.,  13., 209.,\n",
       "       108., 203., 150., 156., 124., 132., 225.,  21., 230.,  73., 250.,\n",
       "        83., 155., 141., 238., 236., 112.,  14.,  72., 104., 221.,  35.,\n",
       "       253.,  13., 155.,  79., 253.,  46.,  38.,  48., 194.,   6., 100.,\n",
       "       135.,  73.,  83., 226.,  54.,  43.,  54., 163.,  72.,  97., 164.,\n",
       "        79., 115., 121.,   8., 194.,  23.,  81., 235., 166.,  17., 169.,\n",
       "       141.,  99.,  50.,  18., 178.,  17.,  49., 194.,  65.,  54., 205.,\n",
       "        45., 187., 226.,  84.,  79., 227., 204., 195.,  10.,  74., 238.,\n",
       "       250., 226.,  16., 112., 152.,  95., 193.,  85., 190.,  55.,  79.,\n",
       "        18., 166.,  16., 170., 175., 184.,  20.,  59.,  98., 153., 212.,\n",
       "       149., 160., 157., 116., 208.,  94., 240.,  96.,  41.,  66., 178.,\n",
       "        42.,  30., 109., 251., 186.,  80.,  94.,  57., 105.,  42.,  59.,\n",
       "       177.,  48., 178.,  79., 216., 105., 100., 101., 177., 100., 150.,\n",
       "        63., 115., 111., 141., 248., 204.,   2., 174.,  55., 170., 208.,\n",
       "        69.,  73., 186., 204., 171.,  52.,  80., 232.,  49.,  70., 161.,\n",
       "        17., 205.,  10.,  97., 131.,  11., 143., 143.,  30.,  61.,  44.,\n",
       "        17.,  98.,  91., 125., 236., 137., 105., 129., 132., 249.,  91.,\n",
       "       112., 106., 165.,  68., 146.,  92.,  40.,  32., 212., 105., 114.,\n",
       "       117.,  45., 102., 214., 208.,  12., 107.,  31.,  17., 100., 193.,\n",
       "        14., 154., 166., 109.,   8., 195., 154.,   4., 199.,  48.,  99.,\n",
       "       232., 194., 170.,  84., 241.,  35.,  73., 230.,  78., 136., 183.,\n",
       "       200., 116.,  91., 221.,  42.,  87., 100., 147., 254., 146., 224.,\n",
       "       207.,  79.,  34., 199., 225.,  99., 204.,  66., 170.,  84.,  81.,\n",
       "        20., 185.,  55., 167.,  79., 208., 194.,  84., 210.,  67., 148.,\n",
       "       159., 236., 140., 250.,  55., 151., 127.,  74., 151.,  21., 175.,\n",
       "       109., 196.,  42., 153., 188., 226., 115., 154.,  44., 144., 110.,\n",
       "       138., 238.], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56f9eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf02ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
