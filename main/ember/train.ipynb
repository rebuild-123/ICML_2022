{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac8a951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import multiprocessing as mp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "from src.model import *\n",
    "# from src.util import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "373482b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_path = '/workdir/security/home/junjiehuang2468/paper/trained_models_weight/ember/'\n",
    "data_path = \"/workdir/security/home/junjiehuang2468/paper/data/ember2018/\"\n",
    "train_data_path = data_path + \"malwares/\"  # Training data\n",
    "train_label_path = data_path + \"train_labels.csv\"  # Training label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecec6fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = True if torch.cuda.is_available() else False\n",
    "NUM_WORKERS = 24  # Number of cores to use for data loader\n",
    "BATCH_SIZE = 25  #\n",
    "LEAVE_BIT_NUMBER = 20000\n",
    "KERNEL_SIZE = 500  # Kernel size & stride for Malconv (defualt : 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27857b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.read_csv(data_path + 'train_dataset.csv')\n",
    "validset = pd.read_csv(data_path + 'valid_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d48ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExeDataset(Dataset):\n",
    "    def __init__(self, malware_names, data_path, labels, leave_bit_num):\n",
    "        self.malware_names = malware_names\n",
    "        self.data_path = data_path\n",
    "        self.labels = labels\n",
    "        self.leave_bit_num = leave_bit_num\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.malware_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with open(self.data_path + self.malware_names[idx] + '.txt','rb') as fp:\n",
    "            data = [bit+1 for bit in fp.read()[:self.leave_bit_num]]\n",
    "            padding = [0]*(self.leave_bit_num-len(data))\n",
    "            data = data + padding\n",
    "\n",
    "        return np.array(data), np.array([self.labels[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b423a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ExeDataset(\n",
    "    trainset[\"id\"].tolist(), \n",
    "    train_data_path, \n",
    "    trainset[\"labels\"].tolist(), \n",
    "    LEAVE_BIT_NUMBER\n",
    ")\n",
    "valid_dataset = ExeDataset(\n",
    "    validset[\"id\"].tolist(), \n",
    "    train_data_path, \n",
    "    validset[\"labels\"].tolist(), \n",
    "    LEAVE_BIT_NUMBER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dff087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = NUM_WORKERS,\n",
    "    pin_memory = True\n",
    ")\n",
    "validloader = DataLoader(\n",
    "    dataset = valid_dataset,\n",
    "    batch_size = 1024,\n",
    "    shuffle = True,\n",
    "    num_workers = NUM_WORKERS,\n",
    "    pin_memory = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "281d4c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, data_length = 2e6, kernel_size = 500):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_layer_1 = nn.Conv1d(4, 128, kernel_size, stride = kernel_size, bias = True)\n",
    "        # self.bn_1 = nn.BatchNorm1d(128)\n",
    "        self.conv_layer_2 = nn.Conv1d(4, 128, kernel_size, stride = kernel_size, bias = True)\n",
    "        self.pool_layer_2 = nn.MaxPool1d(data_length//kernel_size)\n",
    "        self.fc_layer_3 = nn.Linear(128, 128)\n",
    "        self.fc_layer_4 = nn.Linear(128, 2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.transpose(-1,-2)\n",
    "        x_conv_1 = self.conv_layer_1(x[:,:4,:])\n",
    "        x_conv_2 = torch.sigmoid(self.conv_layer_2(x[:,4:,:]))\n",
    "        x = x_conv_1*x_conv_2\n",
    "        del x_conv_1,x_conv_2\n",
    "        x = self.pool_layer_2(x).squeeze()\n",
    "        x = self.fc_layer_3(x)\n",
    "        x = self.fc_layer_4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9e7dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_def(model,trainloader,loss_fn,optim,cuda=True):\n",
    "    model.train()\n",
    "    ls = []\n",
    "    bar = tqdm(trainloader)\n",
    "    for step, (batch_data,batch_label) in enumerate(bar):\n",
    "        optim.zero_grad()\n",
    "        batch_data = batch_data.cuda() if cuda else batch_data\n",
    "        batch_label = batch_label.cuda() if cuda else batch_label\n",
    "        batch_label = batch_label.squeeze()\n",
    "        temp = torch.zeros((len(batch_label),2))\n",
    "        for idx,target in enumerate(batch_label.squeeze()): temp[idx,target] = 1\n",
    "        temp_label = temp.cuda() if cuda else temp\n",
    "        # label = label.squeeze() - 1\n",
    "        pred = model(batch_data)\n",
    "        loss = loss_fn(pred, temp_label)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        _, predicted = torch.max(pred, 1)\n",
    "        temp_ls = (batch_label.cpu().data.numpy() == predicted.cpu().data.numpy()).tolist()\n",
    "        ls.extend(temp_ls)\n",
    "        bar.set_description(f'train: {np.mean(ls):.6}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a784fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_def(model,validloader,cuda=True):\n",
    "    model.eval()\n",
    "    ls = []\n",
    "    bar = tqdm(validloader)\n",
    "    for step, (batch_data,batch_label) in enumerate(bar):\n",
    "        optim.zero_grad()\n",
    "        batch_data = batch_data.cuda() if cuda else batch_data\n",
    "        batch_label = batch_label.cuda() if cuda else batch_label\n",
    "        batch_label = batch_label.squeeze()\n",
    "        temp = torch.zeros((len(batch_label),2))\n",
    "        for idx,target in enumerate(batch_label.squeeze()): temp[idx,target] = 1\n",
    "        temp_label = temp.cuda() if cuda else temp\n",
    "        # label = label.squeeze() - 1\n",
    "        pred = model(batch_data)\n",
    "        _, predicted = torch.max(pred, 1)\n",
    "        temp_ls = (batch_label.cpu().data.numpy() == predicted.cpu().data.numpy()).tolist()\n",
    "        ls.extend(temp_ls)\n",
    "        bar.set_description(f'test: {np.mean(ls):.6}')\n",
    "    return model,np.mean(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8123ec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dir = str(datetime.now())\n",
    "time_dir = time_dir[:time_dir.rfind(':')]\n",
    "os.mkdir(f'{trained_model_path}{time_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ce43ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(data_length=LEAVE_BIT_NUMBER,kernel_size=KERNEL_SIZE)\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "optim = Adam(model.parameters())\n",
    "\n",
    "model = model.cuda() if CUDA else model\n",
    "ce_loss = ce_loss.cuda() if CUDA else ce_less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b54da16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.85696: 100%|██████████| 19200/19200 [08:35<00:00, 37.27it/s] \n",
      "test: 0.880583: 100%|██████████| 118/118 [00:26<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.910431: 100%|██████████| 19200/19200 [08:23<00:00, 38.16it/s]\n",
      "test: 0.88955: 100%|██████████| 118/118 [00:25<00:00,  4.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.935844: 100%|██████████| 19200/19200 [08:15<00:00, 38.74it/s]\n",
      "test: 0.893517: 100%|██████████| 118/118 [00:25<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.95345: 100%|██████████| 19200/19200 [08:13<00:00, 38.94it/s] \n",
      "test: 0.890633: 100%|██████████| 118/118 [00:25<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.963206: 100%|██████████| 19200/19200 [08:12<00:00, 38.98it/s]\n",
      "test: 0.89335: 100%|██████████| 118/118 [00:25<00:00,  4.62it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.970092: 100%|██████████| 19200/19200 [08:30<00:00, 37.61it/s]\n",
      "test: 0.895942: 100%|██████████| 118/118 [00:26<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.974992: 100%|██████████| 19200/19200 [08:16<00:00, 38.70it/s]\n",
      "test: 0.895858: 100%|██████████| 118/118 [00:25<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.977944: 100%|██████████| 19200/19200 [08:11<00:00, 39.07it/s]\n",
      "test: 0.895258: 100%|██████████| 118/118 [00:25<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.980673: 100%|██████████| 19200/19200 [08:17<00:00, 38.58it/s]\n",
      "test: 0.891858: 100%|██████████| 118/118 [00:25<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.982406: 100%|██████████| 19200/19200 [08:09<00:00, 39.25it/s]\n",
      "test: 0.8942: 100%|██████████| 118/118 [00:25<00:00,  4.62it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.983752: 100%|██████████| 19200/19200 [08:09<00:00, 39.19it/s]\n",
      "test: 0.894433: 100%|██████████| 118/118 [00:25<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.985356: 100%|██████████| 19200/19200 [08:20<00:00, 38.35it/s]\n",
      "test: 0.895417: 100%|██████████| 118/118 [00:26<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.986369: 100%|██████████| 19200/19200 [08:18<00:00, 38.52it/s]\n",
      "test: 0.893383: 100%|██████████| 118/118 [00:25<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.987156: 100%|██████████| 19200/19200 [08:08<00:00, 39.27it/s]\n",
      "test: 0.896192: 100%|██████████| 118/118 [00:25<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.987738: 100%|██████████| 19200/19200 [08:10<00:00, 39.15it/s]\n",
      "test: 0.896383: 100%|██████████| 118/118 [00:25<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.988642: 100%|██████████| 19200/19200 [08:10<00:00, 39.18it/s]\n",
      "test: 0.893042: 100%|██████████| 118/118 [00:25<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.988952: 100%|██████████| 19200/19200 [08:24<00:00, 38.08it/s]\n",
      "test: 0.897317: 100%|██████████| 118/118 [00:26<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.989471: 100%|██████████| 19200/19200 [08:25<00:00, 37.98it/s]\n",
      "test: 0.895033: 100%|██████████| 118/118 [00:25<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0.991459:  44%|████▎     | 8352/19200 [02:46<04:42, 38.45it/s]Exception in thread Thread-41:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/workdir/security/home/junjiehuang2468/.local/lib/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py\", line 28, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/workdir/security/home/junjiehuang2468/.local/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 289, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 493, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 737, in answer_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "train: 0.991459:  44%|████▎     | 8355/19200 [02:47<03:37, 49.97it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0bc4ae55dc3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mce_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCUDA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCUDA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{trained_model_path}{time_dir}/2w_epoch:{i}_test_acc:{test_acc:.6f}.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-97f853f221f1>\u001b[0m in \u001b[0;36mtrain_def\u001b[0;34m(model, trainloader, loss_fn, optim, cuda)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    print(i)\n",
    "    model = train_def(model,trainloader,ce_loss,optim,CUDA)\n",
    "    model,test_acc = valid_def(model,validloader,CUDA)\n",
    "    save_path = f'{trained_model_path}{time_dir}/2w_epoch:{i}_test_acc:{test_acc:.6f}.pt'\n",
    "    torch.save(model.state_dict(),save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
